{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import random\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from common_utils import DATA_HOME\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "seed = 42\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "from lstm.sales_data import Sales_Dataset\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SALE_HOME = os.path.join(DATA_HOME, \"sales_data\")\n",
    "\n",
    "I, H, H_TGT, B = 68, 33, 36, 4\n",
    "TARGET_DIM = 33\n",
    "HEAD = 11\n",
    "SEQ_LEN = 116\n",
    "INFER_DAYS = 16\n",
    "\n",
    "sd = Sales_Dataset(SALE_HOME, seq_len=SEQ_LEN)\n",
    "test_set, train_set = torch.utils.data.random_split(sd, [0.1, 0.9])\n",
    "train_dl = DataLoader(train_set, shuffle=True, batch_size=B, generator=g)\n",
    "test_dl = DataLoader(test_set, shuffle=True, batch_size=B, generator=g)\n",
    "len(train_dl), len(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dl), len(test_dl))\n",
    "# print(sd.O.describe())\n",
    "# print(sd.TS.describe())\n",
    "# print(sd.S.describe())\n",
    "print(sd[0][0].shape, sd[4][0].shape)\n",
    "# print(sd[4][1].shape)\n",
    "# print(sd[4][0], sd[4][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LSTM, Transformer, Linear\n",
    "from torch.nn import MSELoss\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "class Predictor(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.lstm = LSTM(I, H, num_layers=2, batch_first=True).cuda()\n",
    "        self.trans = Transformer(\n",
    "            d_model=H,\n",
    "            nhead=HEAD,\n",
    "            num_encoder_layers=3,\n",
    "            num_decoder_layers=3,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # self.softmax = torch.nn.Softmax(dim=2)\n",
    "        # self.linear1 = Linear(H_TGT, H)\n",
    "        # self.linear2 = Linear(H, TARGET_DIM)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        h, (_, _) = self.lstm(x1)\n",
    "        # x2 = self.softmax(self.linear1(x2))\n",
    "        h = self.trans(h, x2)\n",
    "        # return self.softmax(self.linear2(h))\n",
    "        return h\n",
    "\n",
    "\n",
    "model = Predictor().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_iter = 1500\n",
    "resume_from = f\"sales_model_{saved_iter}_{B}.pth\"\n",
    "\n",
    "if os.path.exists(resume_from):\n",
    "    model.load_state_dict(torch.load(resume_from))\n",
    "    print(f\"{resume_from} model loaded\")\n",
    "    train_gen = enumerate(train_dl, saved_iter)\n",
    "else:\n",
    "    train_gen = enumerate(train_dl)\n",
    "test_gen = enumerate(test_dl)\n",
    "\n",
    "loss = MSELoss()\n",
    "adam = optim.Adam(model.parameters(), lr=0.001)\n",
    "tr_losses, inf_losses = [], []\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "for tr_idx, (X1, X2, y) in train_gen:\n",
    "    X1 = X1.cuda()\n",
    "    X2 = X2.cuda()\n",
    "    y = y.cuda()\n",
    "\n",
    "    # Train\n",
    "    tr_l, inf_l = 0, 0\n",
    "    yhat = model(X1, X2)\n",
    "    l = loss(yhat, y)\n",
    "    # update parameters\n",
    "    adam.zero_grad()\n",
    "    l.backward()\n",
    "    adam.step()\n",
    "    tr_l += l.item()\n",
    "\n",
    "    # Validate\n",
    "    try:\n",
    "        inf_idx, (X1, X2, y) = next(test_gen)\n",
    "    except StopIteration:  # re-initialize test set if exhausted\n",
    "        test_gen = enumerate(test_dl)\n",
    "        inf_idx, (X1, X2, y) = next(test_gen)\n",
    "\n",
    "    X1 = X1.cuda()\n",
    "    X2 = X2.cuda()\n",
    "    y = y.cuda()\n",
    "    yhat = model(X1, X2)\n",
    "    l = loss(yhat, y)\n",
    "    inf_l += l.item()\n",
    "    tr_losses.append(tr_l / len(train_dl))\n",
    "    inf_losses.append(inf_l / len(test_dl))\n",
    "\n",
    "    # Log and save\n",
    "    if tr_idx and saved_iter != tr_idx and tr_idx % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        plt.plot(\n",
    "            range(saved_iter, saved_iter + len(tr_losses)),\n",
    "            tr_losses,\n",
    "            label=\"train loss\",\n",
    "        )\n",
    "        plt.plot(\n",
    "            range(saved_iter, saved_iter + len(inf_losses)),\n",
    "            inf_losses,\n",
    "            label=\"inf loss\",\n",
    "        )\n",
    "        plt.xlim()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print(\n",
    "            f\"iteration: {tr_idx} train loss: {tr_l / len(train_dl)} inf loss: {inf_l / len(test_dl)}\"\n",
    "        )\n",
    "    if tr_idx and tr_idx % 500 == 0:\n",
    "        torch.save(model.state_dict(), f\"sales_model_{tr_idx}_{B}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(tr_losses)), tr_losses, label=\"train loss\")\n",
    "plt.plot(range(len(inf_losses)), inf_losses, label=\"test loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
