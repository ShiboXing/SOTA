{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from common_utils import set_data_home\n",
    "set_data_home(\"/mnt/d\")\n",
    "from common_utils import DATA_HOME, join\n",
    "from lstm.sales_data import Sales_Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/SOTA/lstm/train_lstm.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/SOTA/lstm/train_lstm.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m sd \u001b[39m=\u001b[39m Sales_Dataset(join(DATA_HOME, \u001b[39m\"\u001b[39;49m\u001b[39msales_data\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/SOTA/lstm/train_lstm.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m dl \u001b[39m=\u001b[39m DataLoader(sd, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/SOTA/lstm/train_lstm.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mlen\u001b[39m(sd)\n",
      "File \u001b[0;32m/mnt/d/SOTA/lstm/../lstm/sales_data.py:64\u001b[0m, in \u001b[0;36mSales_Dataset.__init__\u001b[0;34m(self, dir_pth, is_train)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mO \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(join(dir_pth, \u001b[39m\"\u001b[39m\u001b[39moil.csv\u001b[39m\u001b[39m\"\u001b[39m), index_col\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     63\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mS \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(join(dir_pth, \u001b[39m\"\u001b[39m\u001b[39mstores.csv\u001b[39m\u001b[39m\"\u001b[39m), index_col\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 64\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTR \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(join(dir_pth, \u001b[39m\"\u001b[39;49m\u001b[39mtrain.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m), index_col\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTS \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(join(dir_pth, \u001b[39m\"\u001b[39m\u001b[39mtransactions.csv\u001b[39m\u001b[39m\"\u001b[39m), index_col\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     67\u001b[0m \u001b[39m# preprocess nominal data\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    616\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 617\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1741\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1742\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1749\u001b[0m         nrows\n\u001b[1;32m   1750\u001b[0m     )\n\u001b[1;32m   1751\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:843\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:904\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2050\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sd = Sales_Dataset(join(DATA_HOME, \"sales_data\"))\n",
    "dl = DataLoader(sd, shuffle=True, batch_size=1)\n",
    "len(sd)\n",
    "\n",
    "# print(sd.O.describe())\n",
    "# print(sd.TR.describe())\n",
    "# print(sd.TS.describe())\n",
    "# print(sd.S.describe())\n",
    "# print(sd[4][0].shape)\n",
    "# print(sd[4][1].shape)\n",
    "# print(sd[4][0], sd[4][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/SOTA/lstm/train_lstm.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/SOTA/lstm/train_lstm.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/SOTA/lstm/train_lstm.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/SOTA/lstm/train_lstm.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m dl:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/SOTA/lstm/train_lstm.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m         yhat, (_, _) \u001b[39m=\u001b[39m model(X, (h, c))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/SOTA/lstm/train_lstm.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m         l \u001b[39m=\u001b[39m loss(yhat, y\u001b[39m.\u001b[39mcuda())\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/mnt/d/SOTA/lstm/../lstm/sales_data.py:154\u001b[0m, in \u001b[0;36mSales_Dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39m# make a column for each family of product\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(sale_data\u001b[39m.\u001b[39mfamily):\n\u001b[1;32m    150\u001b[0m     sale_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(\n\u001b[1;32m    151\u001b[0m         [\n\u001b[1;32m    152\u001b[0m             sale_df,\n\u001b[1;32m    153\u001b[0m             pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m--> 154\u001b[0m                 {\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00md\u001b[39m}\u001b[39;00m\u001b[39m_sales\u001b[39m\u001b[39m\"\u001b[39m: sale_data[sale_data\u001b[39m.\u001b[39;49mfamily \u001b[39m==\u001b[39;49m d]\u001b[39m.\u001b[39msales}\n\u001b[1;32m    155\u001b[0m             ),\n\u001b[1;32m    156\u001b[0m         ],\n\u001b[1;32m    157\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    158\u001b[0m     )\n\u001b[1;32m    159\u001b[0m     sale_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(\n\u001b[1;32m    160\u001b[0m         [\n\u001b[1;32m    161\u001b[0m             sale_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    171\u001b[0m     )\n\u001b[1;32m    173\u001b[0m \u001b[39m# fix the data on the missing dates\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py:3887\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3885\u001b[0m \u001b[39m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   3886\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 3887\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_bool_array(key)\n\u001b[1;32m   3889\u001b[0m \u001b[39m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   3890\u001b[0m \u001b[39m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   3891\u001b[0m is_single_key \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py:3949\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3946\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   3948\u001b[0m indexer \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 3949\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_with_is_copy(indexer, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py:4088\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4077\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   4078\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_with_is_copy\u001b[39m(\u001b[39mself\u001b[39m, indices, axis: Axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Self:\n\u001b[1;32m   4079\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4080\u001b[0m \u001b[39m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4081\u001b[0m \u001b[39m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4086\u001b[0m \u001b[39m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4087\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4088\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtake(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   4089\u001b[0m     \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   4090\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_get_axis(axis)\u001b[39m.\u001b[39mequals(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py:4068\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4063\u001b[0m     \u001b[39m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4064\u001b[0m     indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\n\u001b[1;32m   4065\u001b[0m         indices\u001b[39m.\u001b[39mstart, indices\u001b[39m.\u001b[39mstop, indices\u001b[39m.\u001b[39mstep, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp\n\u001b[1;32m   4066\u001b[0m     )\n\u001b[0;32m-> 4068\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mtake(\n\u001b[1;32m   4069\u001b[0m     indices,\n\u001b[1;32m   4070\u001b[0m     axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_block_manager_axis(axis),\n\u001b[1;32m   4071\u001b[0m     verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   4072\u001b[0m )\n\u001b[1;32m   4073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[39m=\u001b[39mnew_data\u001b[39m.\u001b[39maxes)\u001b[39m.\u001b[39m__finalize__(\n\u001b[1;32m   4074\u001b[0m     \u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4075\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py:874\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[39m# Caller is responsible for ensuring indexer annotation is accurate\u001b[39;00m\n\u001b[1;32m    873\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[axis]\n\u001b[0;32m--> 874\u001b[0m indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39;49mverify)\n\u001b[1;32m    876\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m    877\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreindex_indexer(\n\u001b[1;32m    878\u001b[0m     new_axis\u001b[39m=\u001b[39mnew_labels,\n\u001b[1;32m    879\u001b[0m     indexer\u001b[39m=\u001b[39mindexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    882\u001b[0m     copy\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    883\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexers/utils.py:275\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mempty(\u001b[39m0\u001b[39m, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n\u001b[1;32m    274\u001b[0m mask \u001b[39m=\u001b[39m indices \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 275\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39;49many():\n\u001b[1;32m    276\u001b[0m     indices \u001b[39m=\u001b[39m indices\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    277\u001b[0m     indices[mask] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m n\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:58\u001b[0m, in \u001b[0;36m_any\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_any\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     56\u001b[0m     \u001b[39m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[39mif\u001b[39;00m where \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         \u001b[39mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims)\n\u001b[1;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims, where\u001b[39m=\u001b[39mwhere)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.nn import LSTM\n",
    "from torch.nn import MSELoss\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "I, H = 71, 33\n",
    "epochs = 10\n",
    "\n",
    "model = LSTM(71, 33, batch_first=True).cuda()\n",
    "loss = MSELoss()\n",
    "adam = optim.Adam(model.parameters(), lr=0.001)\n",
    "h, c = torch.randn(1,1, 33, dtype=torch.float32).cuda(), torch.randn(1,1, 33, dtype=torch.float32).cuda()\n",
    "model.train()\n",
    "losses = []\n",
    "for _ in range(epochs):\n",
    "    for X, y in dl:\n",
    "        yhat, (_, _) = model(X, (h, c))\n",
    "        l = loss(yhat, y.cuda())\n",
    "\n",
    "        adam.zero_grad()\n",
    "        l.backward()\n",
    "        adam.step()\n",
    "        losses.append(l.item())\n",
    "plt.plot(range(len(dl)) * epochs, losses)\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
