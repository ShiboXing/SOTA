{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"..\")\n",
    "from models import YOLOv1\n",
    "from data.VOC_Dataset import VOC_Dataset\n",
    "from common_utils import DATA_HOME\n",
    "\n",
    "from ipdb import set_trace\n",
    "from torch.utils.data import DataLoader\n",
    "from multiprocessing import cpu_count\n",
    "import random \n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "_voc_root = f\"{DATA_HOME}/VOCdevkit/VOC2007\"\n",
    "voc_ds = VOC_Dataset(_voc_root)\n",
    "train_indices, test_indices = train_test_split(list(range(len(voc_ds))), test_size=0.2, random_state=1)\n",
    "train_set = Subset(voc_ds, train_indices)\n",
    "test_set = Subset(voc_ds, test_indices)\n",
    "\n",
    "BS = 2\n",
    "S = 7 # num of rows/cols\n",
    "C = 20 # num of classes\n",
    "B = 2 # num of bounding boxes\n",
    "\n",
    "lamba_coord = 5\n",
    "lamba_noobj = 0.5\n",
    "\n",
    "def inf_test_gen(data_loader):\n",
    "    while True:\n",
    "        for id, batch in enumerate(data_loader):\n",
    "            yield id, batch\n",
    "        \n",
    "\n",
    "def collate_fn(data):\n",
    "    # output: 7 * 7 * 30\n",
    "    # S * S * ((x, y, w, h, confidence) * B=2 + C=20)\n",
    "    # make img batch and label batch\n",
    "    imgs, labels, classes = zip(*data)\n",
    "    # stride = 1. / S\n",
    "    # imgs = np.array()\n",
    "    # for i, batch in enumerate(data):\n",
    "    #     imgs = np.concatenate(imgs, batch[0])\n",
    "    #     for x, y, w, h in batch[1]:\n",
    "    #         xi, yi = int(x // stride), int(y // stride)\n",
    "            \n",
    "    # set_trace()\n",
    "    # # inhomegenous shape label, since each image has different number of objects\n",
    "    # # label's dimension: (Batch size, # of objects in each image, 4 coords)\n",
    "    # label_mat = torch.zeros((len(labels), S, S, 30))\n",
    "    # coord_mat = torch.tensor(labels)\n",
    "    \n",
    "    # for i, l in enumerate(labels):\n",
    "    #     pass\n",
    "            \n",
    "\n",
    "    return torch.tensor(np.array(imgs), dtype=torch.float), labels, classes\n",
    "    \n",
    "if platform.system() == \"Windows\":\n",
    "    train_loader = DataLoader(train_set, batch_size=BS, pin_memory=True, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_set, batch_size=BS, pin_memory=True, shuffle=True, collate_fn=collate_fn)\n",
    "else:\n",
    "    train_loader = DataLoader(train_set, batch_size=BS, pin_memory=True, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_set, batch_size=BS, pin_memory=True, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "test_loader = inf_test_gen(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLOv1().to(device=device)\n",
    "\n",
    "# Apply Xavier initialization to the model's weights\n",
    "# for name, param in yolo.named_parameters():\n",
    "#     if 'weight' in name:\n",
    "#         torch.nn.init.kaiming_normal_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import IOU\n",
    "from collections import defaultdict as dd\n",
    "\n",
    "def yolo_loss(res_mat: torch.tensor, label_mat: list, class_mat: list, loss_df: pd.DataFrame):\n",
    "    \"\"\"calcalate batch yolo loss, @param res_mat: (batch_size, B*5+C, S, S)\"\"\"\n",
    "    loss1 = torch.tensor(0.).to(device=device)\n",
    "    loss2 = torch.tensor(0.).to(device=device)\n",
    "    loss3 = torch.tensor(0.).to(device=device)\n",
    "    loss4 = torch.tensor(0.).to(device=device)\n",
    "    loss5 = torch.tensor(0.).to(device=device)\n",
    "    # calculate loss for every bounding box in every cell\n",
    "    for b, batch in enumerate(res_mat):\n",
    "        # assign labels bbox to cell indices\n",
    "        stride = 1. / S\n",
    "        label_inds = dd(list)\n",
    "        label_class = {}\n",
    "        for idx, (x, y, w, h) in enumerate(label_mat[b]):\n",
    "            xi, yi = int(x // stride), int(y // stride)\n",
    "            label_inds[(xi, yi)].append((x, y, w, h))\n",
    "            label_class[(x, y, w, h)] = class_mat[b][idx]\n",
    "\n",
    "        # print(\"label class\", label_class, b, batch.shape)\n",
    "        # iterate cell and calculate loss\n",
    "        for i in range(batch.shape[1]):\n",
    "            for j in range(batch.shape[2]):\n",
    "                cell = batch[:, i, j]\n",
    "\n",
    "                if (i, j) in label_inds:\n",
    "                    yprobs = torch.tensor([0.] * C).to(device=device)\n",
    "                    for x, y, w, h in label_inds[i, j]:\n",
    "                        max_iou_k, max_iou = 0, 0\n",
    "                        \n",
    "                        # select the bbox with the highest iou\n",
    "                        for k in range(0, B*5, 5):\n",
    "                            x_, y_, w_, h_, c_ = cell[k:k+5]\n",
    "                            curr_iou = (IOU((x, y, w, h), (x_, y_, w_, h_))) # yolo loss term 3\n",
    "                            if curr_iou > max_iou:\n",
    "                                max_iou_k = k\n",
    "                                \n",
    "                        # use the bbox to calculate coord loss\n",
    "                        k = max_iou_k\n",
    "                        x_, y_, w_, h_, c_ = cell[k:k+5]\n",
    "                        loss1 += lamba_coord * ((x-x_) ** 2 + (y-y_) ** 2) # yolo loss term 1\n",
    "                        loss2 += lamba_coord * ((w ** 0.5 - w_.sqrt())**2 + (h ** 0.5 - h_.sqrt())**2) # yolo loss term 2\n",
    "                        loss3 += (IOU((x, y, w, h), (x_, y_, w_, h_)) - c_) ** 2 # yolo loss term 3\n",
    "                        yprobs[label_class[x, y, w, h]] = 1.  \n",
    "                    loss5 += ((yprobs - cell[-C:]) ** 2).sum() # yolo loss term 5\n",
    "                else:\n",
    "                    for k in range(4, B*5, 5):\n",
    "                        _c = cell[k]\n",
    "                        loss4 += _c ** 2 * lamba_noobj # yolo loss term 4\n",
    "        # print(\"xywh: \" , x_, y_, w_, h_, c_)\n",
    "        # print(\"label: \", x, y, w, h)\n",
    "    loss_df = pd.concat((loss_df, pd.DataFrame([[loss1.item(), loss2.item(), loss3.item(), loss4.item(), loss5.item()]], columns=loss_df.columns)), ignore_index=True)\n",
    "    return loss1 + loss2 + loss3 + loss4 + loss5, loss_df\n",
    "    # print(\"ret: \", res_mat.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import modules\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# IO\n",
    "save_dir = os.path.expanduser(os.environ[\"YOLO_MODELS\"])\n",
    "train_loss_df = pd.DataFrame(columns=[\"l1\", \"l2\", \"l3\", \"l4\", \"l5\"])\n",
    "val_loss_df = pd.DataFrame(columns=[\"l1\", \"l2\", \"l3\", \"l4\", \"l5\"])\n",
    "print(f\"model save_dir: {save_dir}\")\n",
    "print(f\"train_set size: {len(train_set)}, val_set size: {len(test_set)}\")\n",
    "files = [f for f in os.listdir(save_dir) if \".pth\" in f]\n",
    "epoch = 0\n",
    "if files:\n",
    "    checkpoint_pth = save_dir+\"/\"+max(files)\n",
    "    yolo.load_state_dict(torch.load(checkpoint_pth)[\"model\"])\n",
    "    print(\"loaded model checkpoint: \", checkpoint_pth)\n",
    "\n",
    "# label utils\n",
    "# def wrangle_labels(batch, labels, classes):\n",
    "    # \"\"\"Transform labels into tensor (B, S, S, 2 * B + C)\"\"\"\n",
    "    # label_tensor = torch.zeros((B, S, S, 2 * B + C))\n",
    "    # for b in \n",
    "\n",
    "for param in yolo.features.parameters():\n",
    "    param.requires_grad = False\n",
    "optimizer = optim.SGD(yolo.parameters(), lr=1e-4, momentum=0.9, weight_decay=5e-4)\n",
    "torch.cuda.empty_cache()\n",
    "# calculate training time\n",
    "start_time = time.time()\n",
    "while epoch < 100:\n",
    "    for _id, (batch, labels, classes) in enumerate(train_loader):\n",
    "        \n",
    "        # clear gradient graph\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward-propagate\n",
    "        res = yolo(batch.to(device=device))\n",
    "        # print(res.shape, len(labels[2]), classes[2])\n",
    "        train_loss, train_loss_df = yolo_loss(res, labels, classes, train_loss_df)\n",
    "        # set_trace\n",
    "\n",
    "        # back-propagate\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate validation errors\n",
    "        _, (batch, labels, classes) = next(test_loader)\n",
    "        with torch.no_grad():\n",
    "            res = yolo(batch.to(device=device))\n",
    "            val_loss, val_loss_df = yolo_loss(res, labels, classes, val_loss_df)\n",
    "            \n",
    "        # perform IO\n",
    "        if epoch and epoch % 2 and _id == 1000:\n",
    "            # save model \n",
    "            checkpoint = {\n",
    "                'model': yolo.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'iteration': _id,\n",
    "                'train_loss': train_loss,\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{save_dir}/yolov1_{epoch}_{_id}.pth\")\n",
    "            \n",
    "            # show time elapse\n",
    "            print(f\"Epoch {epoch}, iteration: {_id}, train loss: {train_loss}, val loss: {val_loss}\")\n",
    "            train_loss_df.to_csv(f\"{save_dir}/train_loss_latest.csv\")\n",
    "            val_loss_df.to_csv(f\"{save_dir}/val_loss_latest.csv\")\n",
    "    epoch += 1\n",
    "    \n",
    "        # if _id == 2000:\n",
    "            # set_trace()\n",
    "            # end_time = time.time()\n",
    "            # print(\"1000 iterations cost: {:.2f} seconds\".format(end_time - start_time))\n",
    "            # start_time = end_time\n",
    "        # showing the image with labels\n",
    "        # res_img = Image.fromarray((batch[0] * 255).permute(1, 2, 0).byte().numpy())\n",
    "        # draw = ImageDraw.Draw(res_img)\n",
    "        # for pc in labels[0]:\n",
    "            # draw.rectangle((448*pc[0], 448*pc[1], 448*pc[2], 448*pc[3]), outline=\"red\")\n",
    "        # res_img.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
