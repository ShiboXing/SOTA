{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"..\")\n",
    "from models import YOLOv1\n",
    "from data.VOC_Dataset import VOC_Dataset\n",
    "from common_utils import DATA_HOME\n",
    "\n",
    "from ipdb import set_trace\n",
    "from torch.utils.data import DataLoader\n",
    "from multiprocessing import cpu_count\n",
    "import random \n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# torch.multiprocessing.set_start_method(\"spawn\", force=True)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "_voc_root = f\"{DATA_HOME}/VOCdevkit/VOC2007\"\n",
    "voc_ds = VOC_Dataset(_voc_root)\n",
    "train_indices, test_indices = train_test_split(list(range(len(voc_ds))), test_size=0.2, random_state=1)\n",
    "train_set = Subset(voc_ds, train_indices)\n",
    "test_set = Subset(voc_ds, test_indices)\n",
    "\n",
    "BS = 2 # batch size\n",
    "S = 7 # num of rows/cols\n",
    "C = 20 # num of classes\n",
    "B = 2 # num of bounding boxes\n",
    "BOX = 5 # num of values for each bbox\n",
    "\n",
    "lambda_coord = 5\n",
    "lambda_noobj = 1\n",
    "\n",
    "def inf_test_gen(data_loader):\n",
    "    while True:\n",
    "        for id, batch in enumerate(data_loader):\n",
    "            yield id, batch\n",
    "        \n",
    "\n",
    "def collate_fn(data):\n",
    "    # output: 7 * 7 * 30\n",
    "    # S * S * ((x, y, w, h, confidence) * B=2 + C=20)\n",
    "    # make img batch and label batch\n",
    "    imgs, labels, classes = zip(*data)\n",
    "    imgs = torch.tensor(np.array(imgs), dtype=torch.float16)\n",
    "    stride = 1. / S\n",
    "    label_mat = torch.zeros((len(imgs), BOX * B + C, S, S), dtype=torch.float16)\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels[i])):\n",
    "            x, y, _, _= labels[i][j]\n",
    "            xi, yi = int(x // stride), int(y // stride)\n",
    "            cell = label_mat[i, :, xi, yi]\n",
    "            cell[:5] = cell[5:10] = torch.tensor([*labels[i][j], 1], dtype=torch.float16) # assign coords\n",
    "            cell[BOX * B + classes[i][j]] = 1.0 # assign class\n",
    "    return imgs, label_mat\n",
    "    \n",
    "if platform.system() == \"Windows\":\n",
    "    train_loader = DataLoader(train_set, batch_size=BS, pin_memory=False, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_set, batch_size=1, pin_memory=False, shuffle=True, collate_fn=collate_fn)\n",
    "    save_dir = os.path.expanduser(\"~/YOLO_MODELS\")\n",
    "else:\n",
    "    train_loader = DataLoader(train_set, batch_size=BS, pin_memory=False, shuffle=True, num_workers=1, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_set, batch_size=1, pin_memory=False, shuffle=True, num_workers=1, collate_fn=collate_fn)\n",
    "    save_dir = os.path.expanduser(os.environ[\"YOLO_MODELS\"])\n",
    "test_loader = inf_test_gen(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLOv1().to(device=device).half()\n",
    "\n",
    "# Apply initialization to the model's weights\n",
    "# for name, param in yolo.named_parameters():\n",
    "#     if 'weight' in name:\n",
    "#         torch.nn.init.kaiming_normal_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import IOU\n",
    "from collections import defaultdict as dd\n",
    "\n",
    "mse_loss = torch.nn.MSELoss(reduction=\"none\")\n",
    "def yolo_loss(yhat: torch.Tensor, y: torch.Tensor, loss_df: pd.DataFrame):\n",
    "    \"\"\"calcalate batch yolo loss, @param res_mat: (batch_size, B*5+C, S, S)\"\"\"\n",
    "    loss1 = loss2 = loss3 = loss4 = loss5 = 0.\n",
    "    # calculate loss for every bounding box in every cell\n",
    "    loss1 = (y[:, 4, :, :] * (lambda_coord * mse_loss(yhat[:, :2, :, :], y[:, :2, :, :]) + mse_loss(yhat[:, 5:7, :, :], y[:, 5:7, :, :]))).sum()\n",
    "    loss2 = (y[:, 4, :, :] * (lambda_coord * (yhat[:, 2:4, :, :].sqrt() - y[:, 2:4, :, :].sqrt()) ** 2 + (yhat[:, 7:9, :, :].sqrt() - y[:, 7:9, :, :].sqrt()) ** 2)).sum()\n",
    "    loss3 = (y[:, 4, :, :] * mse_loss(yhat[:, 4, :, :], y[:, 4, :, :])).sum()\n",
    "    loss4 = lambda_noobj * (yhat[:, 4, :, :][y[:, 4, :, :]==0] ** 2 + yhat[:, 9, :, :][y[:, 9, :, :]==0] ** 2).sum()\n",
    "    obj_mask = (y[:, 4, :, :] == 1).unsqueeze(1).expand(-1, 20, -1, -1)\n",
    "    loss5 = mse_loss(y[:, -C:, :, :][obj_mask], yhat[:, -C:, :, :][obj_mask]).sum()\n",
    "\n",
    "    loss_df = pd.concat((loss_df, pd.DataFrame([[loss1.item(), loss2.item(), loss3.item(), loss4.item(), loss5.item()]], columns=loss_df.columns)), ignore_index=True)\n",
    "    return loss1 + loss2 + loss3 + loss4 + loss5, loss_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import modules\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# IO\n",
    "train_loss_fname = \"train_loss_latest.csv\"\n",
    "val_loss_fname = \"val_loss_latest.csv\"\n",
    "train_loss_df = pd.DataFrame(columns=[\"l1\", \"l2\", \"l3\", \"l4\", \"l5\"])\n",
    "val_loss_df = pd.DataFrame(columns=[\"l1\", \"l2\", \"l3\", \"l4\", \"l5\"])\n",
    "print(f\"model save_dir: {save_dir}\")\n",
    "print(f\"train_set size: {len(train_set)}, val_set size: {len(test_set)}\")\n",
    "files = [f for f in os.listdir(save_dir) if \".pth\" in f]\n",
    "epoch = 0\n",
    "\n",
    "if files:\n",
    "    max_f = max(files)\n",
    "    epoch = int(max_f.split('_')[1])\n",
    "    checkpoint_pth = save_dir+\"/\"+max_f\n",
    "    yolo.load_state_dict(torch.load(checkpoint_pth)[\"model\"])\n",
    "    print(\"loaded model checkpoint: \", checkpoint_pth)\n",
    "    train_loss_df = pd.read_csv(f\"{save_dir}/{train_loss_fname}\", index_col=None)\n",
    "    val_loss_df = pd.read_csv(f\"{save_dir}/{val_loss_fname}\", index_col=None)\n",
    "    print(\"loaded model loss dataframe\")\n",
    "\n",
    "for param in yolo.features.parameters():\n",
    "    param.requires_grad = False\n",
    "optimizer = optim.SGD(yolo.parameters(), lr=1e-4, momentum=0.9, weight_decay=5e-4)\n",
    "torch.cuda.empty_cache()\n",
    "# calculate training time\n",
    "start_time = time.time()\n",
    "while epoch < 100:\n",
    "    for _id, (img, label) in enumerate(train_loader):\n",
    "        if len(img) != len(label): continue # skip incomplete batch at last\n",
    "        # clear gradient graph\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward-propagate\n",
    "        res = yolo(img.to(device=device))\n",
    "        # print(res.shape, len(labels[2]), classes[2])\n",
    "        train_loss, train_loss_df = yolo_loss(res, label.to(device), train_loss_df)\n",
    "        # set_trace\n",
    "\n",
    "        # back-propagate\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate validation errors\n",
    "        _, (t_img, t_label) = next(test_loader)\n",
    "        with torch.no_grad():\n",
    "            res = yolo(t_img.to(device=device))\n",
    "            val_loss, val_loss_df = yolo_loss(res, t_label.to(device), val_loss_df)\n",
    "            \n",
    "        # perform IO\n",
    "        if epoch and epoch % 2 and _id == 1000:\n",
    "            # save model \n",
    "            checkpoint = {\n",
    "                'model': yolo.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'iteration': _id,\n",
    "                'train_loss': train_loss,\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{save_dir}/yolov1_{epoch}_{_id}.pth\")\n",
    "            \n",
    "            # show time elapse\n",
    "            print(f\"Epoch {epoch}, iteration: {_id}, train loss: {train_loss}, val loss: {val_loss}\")\n",
    "            train_loss_df.to_csv(f\"{save_dir}/{train_loss_fname}\")\n",
    "            val_loss_df.to_csv(f\"{save_dir}/{val_loss_fname}\")\n",
    "    epoch += 1\n",
    "    \n",
    "        # if _id == 2000:\n",
    "            # set_trace()\n",
    "            # end_time = time.time()\n",
    "            # print(\"1000 iterations cost: {:.2f} seconds\".format(end_time - start_time))\n",
    "            # start_time = end_time\n",
    "        # showing the image with labels\n",
    "        # res_img = Image.fromarray((batch[0] * 255).permute(1, 2, 0).byte().numpy())\n",
    "        # draw = ImageDraw.Draw(res_img)\n",
    "        # for pc in labels[0]:\n",
    "            # draw.rectangle((448*pc[0], 448*pc[1], 448*pc[2], 448*pc[3]), outline=\"red\")\n",
    "        # res_img.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
