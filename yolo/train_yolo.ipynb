{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x18d4d251070>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import YOLOv1\n",
    "from data.VOC_Dataset import VOC_Dataset\n",
    "from data import DATA_HOME\n",
    "\n",
    "from ipdb import set_trace\n",
    "from torch.utils.data import DataLoader\n",
    "from numpy import array\n",
    "from multiprocessing import cpu_count\n",
    "import random \n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class dict:  {'bicycle': 0, 'train': 1, 'dog': 2, 'pottedplant': 3, 'horse': 4, 'cow': 5, 'person': 6, 'bus': 7, 'cat': 8, 'boat': 9, 'chair': 10, 'car': 11, 'bottle': 12, 'sofa': 13, 'tvmonitor': 14, 'aeroplane': 15, 'motorbike': 16, 'sheep': 17, 'diningtable': 18, 'bird': 19}\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "_voc_root = f\"{DATA_HOME}/VOCdevkit/VOC2007\"\n",
    "voc_ds = VOC_Dataset(_voc_root)\n",
    "train_indices, test_indices = train_test_split(list(range(len(voc_ds))), test_size=0.2, random_state=1)\n",
    "train_set = Subset(voc_ds, train_indices)\n",
    "test_set = Subset(voc_ds, test_indices)\n",
    "\n",
    "BS = 2\n",
    "\n",
    "def inf_test_gen(data_loader):\n",
    "    while True:\n",
    "        for id, batch in enumerate(data_loader):\n",
    "            yield id, batch\n",
    "        \n",
    "\n",
    "def collate_fn(data):\n",
    "    # output: 7 * 7 * 30\n",
    "    # S * S * ((x, y, w, h, confidence) * B=2 + C=20)\n",
    "    # make img batch and label batch\n",
    "    imgs, labels, classes = zip(*data)\n",
    "    # inhomegenous shape label, since each image has different number of objects\n",
    "    # label's dimension: (Batch size, # of objects in each image, 4 coords)\n",
    "    return torch.tensor(array(imgs), dtype=torch.float), labels, classes\n",
    "    \n",
    "if platform.system() == \"Windows\":\n",
    "    train_loader = DataLoader(train_set, batch_size=BS, pin_memory=True, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_set, batch_size=BS, pin_memory=True, shuffle=True, collate_fn=collate_fn)\n",
    "else:\n",
    "    train_loader = DataLoader(train_set, batch_size=BS, pin_memory=True, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_set, batch_size=BS, pin_memory=True, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "test_loader = inf_test_gen(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yolo = YOLOv1().to(device=device)\n",
    "\n",
    "S = 7 # num of rows/cols\n",
    "C = 20 # num of classes\n",
    "B = 2 # num of bounding boxes\n",
    "\n",
    "lamba_coord = 5\n",
    "lamba_noobj = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import IOU\n",
    "from collections import defaultdict as dd\n",
    "\n",
    "def yolo_loss(res_mat: torch.tensor, label_mat: list, class_mat: list, loss_df: pd.DataFrame):\n",
    "    \"\"\"calcalate batch yolo loss, @param res_mat: (batch_size, B*5+C, S, S)\"\"\"\n",
    "    loss1 = torch.tensor(0.).to(device=device)\n",
    "    loss2 = torch.tensor(0.).to(device=device)\n",
    "    loss3 = torch.tensor(0.).to(device=device)\n",
    "    loss4 = torch.tensor(0.).to(device=device)\n",
    "    loss5 = torch.tensor(0.).to(device=device)\n",
    "    # calculate loss for every bounding box in every cell\n",
    "    for b, batch in enumerate(res_mat):\n",
    "        # assign labels bbox to cell indices\n",
    "        stride = 1. / S\n",
    "        label_inds = dd(list)\n",
    "        label_class = {}\n",
    "        for idx, (x, y, w, h) in enumerate(label_mat[b]):\n",
    "            xi, yi = int(x // stride), int(y // stride)\n",
    "            label_inds[(xi, yi)].append((x, y, w, h))\n",
    "            label_class[(x, y, w, h)] = class_mat[b][idx]\n",
    "        \n",
    "        # print(\"label class\", label_class, b, batch.shape)\n",
    "        # iterate cell and calculate loss\n",
    "        for i in range(batch.shape[1]):\n",
    "            for j in range(batch.shape[2]):\n",
    "                cell = batch[:, i, j]\n",
    "\n",
    "                if (i, j) in label_inds:\n",
    "                    yprobs = torch.tensor([0.] * C).to(device=device)\n",
    "                    for x, y, w, h in label_inds[i, j]:\n",
    "                        for k in range(0, B*5, 5):\n",
    "                            x_, y_, w_, h_, c_ = cell[k:k+5]\n",
    "                            loss1 += lamba_coord * ((x-x_) ** 2 + (y-y_) ** 2) # yolo loss term 1\n",
    "                            loss2 += lamba_coord * ((w - w_.sqrt())**2 + (h ** 0.5 - h_.sqrt())**2) # yolo loss term 2\n",
    "                            loss3 += (IOU((x, y, w, h), (x_, y_, w_, h_)) - c_) ** 2 # yolo loss term 3\n",
    "                        yprobs[label_class[x, y, w, h]] = 1.  \n",
    "                    loss5 += ((yprobs - cell[-C:]) ** 2).sum() # yolo loss term 5\n",
    "                else:\n",
    "                    for k in range(4, B*5, 5):\n",
    "                        _c = cell[k]\n",
    "                        loss4 += _c ** 2 * lamba_noobj # yolo loss term 4\n",
    "        # print(\"xywh: \" , x_, y_, w_, h_, c_)\n",
    "        # print(\"label: \", x, y, w, h)\n",
    "    loss_df = pd.concat((loss_df, pd.DataFrame([[loss1.item(), loss2.item(), loss3.item(), loss4.item(), loss5.item()]], columns=loss_df.columns)), ignore_index=True)\n",
    "    return loss1 + loss2 + loss3 + loss4 + loss5, loss_df\n",
    "    # print(\"ret: \", res_mat.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save_dir: C:\\Users\\sxing/YOLO_MODELS\n",
      "train_set size: 4008, val_set size: 1003\n",
      "> \u001b[1;32mc:\\users\\sxing\\appdata\\local\\temp\\ipykernel_13500\\1547203702.py\u001b[0m(52)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\n",
      "Epoch 0, iteration: 0, train loss: 55.62926483154297, val loss: 62.0623779296875\n",
      "> \u001b[1;32mc:\\users\\sxing\\appdata\\local\\temp\\ipykernel_13500\\1547203702.py\u001b[0m(52)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\n",
      "tensor([[[[0.0458, 0.0325, 0.0515,  ..., 0.1471, 0.1056, 0.1711],\n",
      "          [0.2044, 0.1750, 0.2352,  ..., 0.1821, 0.0569, 0.1141],\n",
      "          [0.4751, 0.3372, 0.3488,  ..., 0.4909, 0.4191, 0.6553],\n",
      "          ...,\n",
      "          [0.6478, 0.6511, 0.5851,  ..., 0.6154, 0.4909, 0.6192],\n",
      "          [0.8010, 0.8101, 0.7809,  ..., 0.8501, 0.6236, 0.7337],\n",
      "          [0.8816, 0.9034, 0.9225,  ..., 0.8959, 0.9144, 0.8300]],\n",
      "\n",
      "         [[0.0436, 0.2573, 0.3342,  ..., 0.5766, 0.6551, 0.8767],\n",
      "          [0.0546, 0.2850, 0.3878,  ..., 0.5039, 0.8016, 0.8357],\n",
      "          [0.0588, 0.2662, 0.3031,  ..., 0.6978, 0.8252, 0.8003],\n",
      "          ...,\n",
      "          [0.1117, 0.2375, 0.3583,  ..., 0.6073, 0.8272, 0.8320],\n",
      "          [0.2251, 0.3848, 0.4550,  ..., 0.7346, 0.6077, 0.8563],\n",
      "          [0.2619, 0.0834, 0.2713,  ..., 0.7908, 0.8963, 0.8508]],\n",
      "\n",
      "         [[0.2536, 0.3023, 0.1668,  ..., 0.1062, 0.0667, 0.0707],\n",
      "          [0.2861, 0.2967, 0.2629,  ..., 0.1556, 0.1854, 0.0658],\n",
      "          [0.3822, 0.2953, 0.3148,  ..., 0.2459, 0.2773, 0.1090],\n",
      "          ...,\n",
      "          [0.5979, 0.5636, 0.4874,  ..., 0.6244, 0.6595, 0.6211],\n",
      "          [0.8085, 0.7771, 0.6091,  ..., 0.6506, 0.5867, 0.6138],\n",
      "          [0.8843, 0.8069, 0.8050,  ..., 0.7692, 0.6993, 0.7663]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0350, 0.0252, 0.0389,  ..., 0.0529, 0.0573, 0.1211],\n",
      "          [0.0276, 0.0300, 0.0220,  ..., 0.0432, 0.0887, 0.1230],\n",
      "          [0.0335, 0.0241, 0.0399,  ..., 0.0322, 0.0527, 0.1310],\n",
      "          ...,\n",
      "          [0.0356, 0.0430, 0.0251,  ..., 0.0387, 0.0547, 0.1557],\n",
      "          [0.0604, 0.0283, 0.0950,  ..., 0.0604, 0.0698, 0.0914],\n",
      "          [0.0677, 0.0453, 0.0661,  ..., 0.0639, 0.0938, 0.1624]],\n",
      "\n",
      "         [[0.0225, 0.0290, 0.0886,  ..., 0.2022, 0.1483, 0.1008],\n",
      "          [0.0263, 0.0161, 0.0303,  ..., 0.2138, 0.1833, 0.1389],\n",
      "          [0.0339, 0.0228, 0.0232,  ..., 0.0503, 0.0991, 0.1253],\n",
      "          ...,\n",
      "          [0.0357, 0.0258, 0.0317,  ..., 0.0353, 0.0541, 0.1485],\n",
      "          [0.0349, 0.0213, 0.0483,  ..., 0.0555, 0.0708, 0.1223],\n",
      "          [0.0707, 0.0388, 0.0601,  ..., 0.1325, 0.1089, 0.1510]],\n",
      "\n",
      "         [[0.0523, 0.0243, 0.0261,  ..., 0.0472, 0.0559, 0.1276],\n",
      "          [0.0777, 0.0294, 0.0431,  ..., 0.0484, 0.0566, 0.1660],\n",
      "          [0.0568, 0.0956, 0.0920,  ..., 0.0360, 0.0719, 0.1877],\n",
      "          ...,\n",
      "          [0.0579, 0.0579, 0.0472,  ..., 0.0655, 0.0622, 0.1046],\n",
      "          [0.0504, 0.0277, 0.0765,  ..., 0.0483, 0.0724, 0.1208],\n",
      "          [0.0776, 0.0886, 0.0491,  ..., 0.0908, 0.0845, 0.1443]]],\n",
      "\n",
      "\n",
      "        [[[0.0508, 0.0282, 0.0500,  ..., 0.1166, 0.0923, 0.1111],\n",
      "          [0.2632, 0.1811, 0.2415,  ..., 0.1949, 0.1041, 0.0898],\n",
      "          [0.3533, 0.3526, 0.3943,  ..., 0.4310, 0.4198, 0.6455],\n",
      "          ...,\n",
      "          [0.6395, 0.6123, 0.5916,  ..., 0.5069, 0.4901, 0.4912],\n",
      "          [0.7091, 0.8429, 0.7505,  ..., 0.8269, 0.6779, 0.8146],\n",
      "          [0.8951, 0.9094, 0.9281,  ..., 0.8674, 0.8764, 0.7598]],\n",
      "\n",
      "         [[0.0715, 0.1719, 0.3444,  ..., 0.6617, 0.6733, 0.8389],\n",
      "          [0.0668, 0.2341, 0.3615,  ..., 0.5918, 0.8075, 0.8738],\n",
      "          [0.0404, 0.2348, 0.3137,  ..., 0.6168, 0.7376, 0.8095],\n",
      "          ...,\n",
      "          [0.1050, 0.2346, 0.4669,  ..., 0.6367, 0.8327, 0.8208],\n",
      "          [0.1685, 0.3431, 0.5348,  ..., 0.6781, 0.7310, 0.8472],\n",
      "          [0.2038, 0.0597, 0.3543,  ..., 0.7533, 0.8884, 0.8246]],\n",
      "\n",
      "         [[0.2546, 0.2969, 0.1594,  ..., 0.0837, 0.0841, 0.0663],\n",
      "          [0.3483, 0.3291, 0.2107,  ..., 0.1477, 0.1886, 0.0721],\n",
      "          [0.4888, 0.3201, 0.2851,  ..., 0.2755, 0.1916, 0.0892],\n",
      "          ...,\n",
      "          [0.5903, 0.5118, 0.4572,  ..., 0.5670, 0.7073, 0.5464],\n",
      "          [0.7858, 0.7478, 0.6604,  ..., 0.6337, 0.6387, 0.6113],\n",
      "          [0.8497, 0.8220, 0.7797,  ..., 0.7855, 0.6176, 0.7501]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0282, 0.0297, 0.0356,  ..., 0.0421, 0.0625, 0.1161],\n",
      "          [0.0317, 0.0286, 0.0319,  ..., 0.0405, 0.0999, 0.2180],\n",
      "          [0.0362, 0.0521, 0.0500,  ..., 0.0427, 0.0465, 0.1611],\n",
      "          ...,\n",
      "          [0.0605, 0.0486, 0.0378,  ..., 0.0637, 0.0463, 0.1751],\n",
      "          [0.0525, 0.0283, 0.0872,  ..., 0.0747, 0.0476, 0.1097],\n",
      "          [0.0722, 0.0479, 0.0671,  ..., 0.0437, 0.0756, 0.1587]],\n",
      "\n",
      "         [[0.0209, 0.0279, 0.0602,  ..., 0.1374, 0.1207, 0.0979],\n",
      "          [0.0309, 0.0222, 0.0383,  ..., 0.2798, 0.1842, 0.1307],\n",
      "          [0.0277, 0.0213, 0.0218,  ..., 0.0609, 0.0821, 0.1220],\n",
      "          ...,\n",
      "          [0.0436, 0.0387, 0.0477,  ..., 0.0569, 0.0777, 0.1114],\n",
      "          [0.0514, 0.0353, 0.0353,  ..., 0.0715, 0.0681, 0.1043],\n",
      "          [0.0733, 0.0541, 0.0506,  ..., 0.1152, 0.0898, 0.1508]],\n",
      "\n",
      "         [[0.0463, 0.0340, 0.0199,  ..., 0.0427, 0.0602, 0.1280],\n",
      "          [0.0579, 0.0436, 0.0561,  ..., 0.0459, 0.0585, 0.1458],\n",
      "          [0.0664, 0.0953, 0.1041,  ..., 0.0541, 0.0741, 0.1376],\n",
      "          ...,\n",
      "          [0.0561, 0.0568, 0.0415,  ..., 0.0724, 0.0680, 0.1225],\n",
      "          [0.0656, 0.0177, 0.0572,  ..., 0.0499, 0.1033, 0.1561],\n",
      "          [0.0844, 0.0908, 0.0728,  ..., 0.0722, 0.1167, 0.1667]]]],\n",
      "       device='cuda:0')\n",
      "Epoch 0, iteration: 1000, train loss: 4.164348125457764, val loss: 7.522845268249512\n"
     ]
    }
   ],
   "source": [
    "from sys import modules\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "save_dir = os.path.expanduser(os.environ[\"YOLO_MODELS\"])\n",
    "\n",
    "optimizer = optim.Adam(yolo.parameters(), lr=1e-4)\n",
    "torch.cuda.empty_cache()\n",
    "train_loss_df = pd.DataFrame(columns=[\"l1\", \"l2\", \"l3\", \"l4\", \"l5\"])\n",
    "val_loss_df = pd.DataFrame(columns=[\"l1\", \"l2\", \"l3\", \"l4\", \"l5\"])\n",
    "print(f\"model save_dir: {save_dir}\")\n",
    "print(f\"train_set size: {len(train_set)}, val_set size: {len(test_set)}\")\n",
    "# calculate training time\n",
    "start_time = time.time()\n",
    "for epoch in range(100):\n",
    "    for _id, (batch, labels, classes) in enumerate(train_loader):\n",
    "        # clear gradient graph\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward-propagate\n",
    "        res = yolo(batch.to(device=device))\n",
    "        # print(res.shape, len(labels[2]), classes[2])\n",
    "        train_loss, train_loss_df = yolo_loss(res, labels, classes, train_loss_df)\n",
    "        # set_trace\n",
    "\n",
    "        # back-propagate\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate validation errors\n",
    "        _, (batch, labels, classes) = next(test_loader)\n",
    "        with torch.no_grad():\n",
    "            res = yolo(batch.to(device=device))\n",
    "            val_loss, val_loss_df = yolo_loss(res, labels, classes, val_loss_df)\n",
    "            \n",
    "        # record losses\n",
    "        if epoch and epoch % 2 == 0 and _id == 0:\n",
    "\n",
    "            checkpoint = {\n",
    "                'model': yolo.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'iteration': _id,\n",
    "                'train_loss': train_loss,\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{save_dir}/yolov1_{epoch}_{_id}.pth\")\n",
    "        \n",
    "        # show time elapse\n",
    "        if _id % 1000 == 0:\n",
    "            # set_trace()\n",
    "            print(f\"Epoch {epoch}, iteration: {_id}, train loss: {train_loss}, val loss: {val_loss}\")\n",
    "            train_loss_df.to_csv(f\"{save_dir}/train_loss_latest.csv\")\n",
    "            val_loss_df.to_csv(f\"{save_dir}/val_loss_latest.csv\")\n",
    "            # end_time = time.time()\n",
    "            # print(\"1000 iterations cost: {:.2f} seconds\".format(end_time - start_time))\n",
    "            # start_time = end_time\n",
    "        # showing the image with labels\n",
    "        # res_img = Image.fromarray((batch[0] * 255).permute(1, 2, 0).byte().numpy())\n",
    "        # draw = ImageDraw.Draw(res_img)\n",
    "        # for pc in labels[0]:\n",
    "            # draw.rectangle((448*pc[0], 448*pc[1], 448*pc[2], 448*pc[3]), outline=\"red\")\n",
    "        # res_img.show()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
