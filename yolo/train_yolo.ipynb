{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1eee0f50ff0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import YOLOv1\n",
    "from data.VOC_Dataset import VOC_Dataset\n",
    "from data import DATA_HOME\n",
    "\n",
    "from ipdb import set_trace\n",
    "from torch.utils.data import DataLoader\n",
    "from numpy import array\n",
    "from multiprocessing import cpu_count\n",
    "import random \n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class dict:  {'boat': 0, 'cat': 1, 'dog': 2, 'bus': 3, 'sheep': 4, 'cow': 5, 'bottle': 6, 'tvmonitor': 7, 'motorbike': 8, 'chair': 9, 'train': 10, 'sofa': 11, 'bird': 12, 'person': 13, 'aeroplane': 14, 'car': 15, 'horse': 16, 'diningtable': 17, 'bicycle': 18, 'pottedplant': 19}\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "_voc_root = f\"{DATA_HOME}/VOCdevkit/VOC2007\"\n",
    "voc_ds = VOC_Dataset(_voc_root)\n",
    "BS = 2\n",
    "\n",
    "def collate_fn(data):\n",
    "    # output: 7 * 7 * 30\n",
    "    # S * S * ((x, y, w, h, confidence) * B=2 + C=20)\n",
    "    # make img batch and label batch\n",
    "    imgs, labels, classes = zip(*data)\n",
    "    # inhomegenous shape label, since each image has different number of objects\n",
    "    # label's dimension: (Batch size, # of objects in each image, 4 coords)\n",
    "    return torch.tensor(array(imgs), dtype=torch.float), labels, classes\n",
    "    \n",
    "if platform.system() == \"Windows\":\n",
    "    loader = DataLoader(voc_ds, batch_size=BS, pin_memory=True, shuffle=True, collate_fn=collate_fn)\n",
    "else:\n",
    "    loader = DataLoader(voc_ds, batch_size=BS, pin_memory=True, shuffle=True, num_workers=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yolo = YOLOv1().to(device=device)\n",
    "\n",
    "S = 7 # num of rows/cols\n",
    "C = 20 # num of classes\n",
    "B = 2 # num of bounding boxes\n",
    "\n",
    "lamba_coord = 5\n",
    "lamba_noobj = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import IOU\n",
    "from collections import defaultdict as dd\n",
    "\n",
    "def yolo_loss(res_mat: torch.tensor, label_mat: list, class_mat: list, loss_df: pd.DataFrame):\n",
    "    \"\"\"calcalate batch yolo loss, @param res_mat: (batch_size, B*5+C, S, S)\"\"\"\n",
    "    loss1 = torch.tensor(0.).to(device=device)\n",
    "    loss2 = torch.tensor(0.).to(device=device)\n",
    "    loss3 = torch.tensor(0.).to(device=device)\n",
    "    loss4 = torch.tensor(0.).to(device=device)\n",
    "    loss5 = torch.tensor(0.).to(device=device)\n",
    "    # calculate loss for every bounding box in every cell\n",
    "    for b, batch in enumerate(res_mat):\n",
    "        # assign labels bbox to cell indices\n",
    "        stride = 1. / S\n",
    "        label_inds = dd(list)\n",
    "        label_class = {}\n",
    "        for idx, (x, y, w, h) in enumerate(label_mat[b]):\n",
    "            xi, yi = int(x // stride), int(y // stride)\n",
    "            label_inds[(xi, yi)].append((x, y, w, h))\n",
    "            label_class[(x, y, w, h)] = class_mat[b][idx]\n",
    "        \n",
    "        # print(\"label class\", label_class, b, batch.shape)\n",
    "        # iterate cell and calculate loss\n",
    "        for i in range(batch.shape[1]):\n",
    "            for j in range(batch.shape[2]):\n",
    "                cell = batch[:, i, j]\n",
    "\n",
    "                if (i, j) in label_inds:\n",
    "                    yprobs = torch.tensor([0.] * C).to(device=device)\n",
    "                    for x, y, w, h in label_inds[i, j]:\n",
    "                        for k in range(0, B*5, 5):\n",
    "                            x_, y_, w_, h_, c_ = cell[k:k+5]\n",
    "                            loss1 += lamba_coord * ((x-x_) ** 2 + (y-y_) ** 2) # yolo loss term 1\n",
    "                            loss2 += lamba_coord * ((w ** 0.5 - abs(w_) ** 0.5)**2 + (h ** 0.5 - abs(h_) ** 0.5)**2) # yolo loss term 2\n",
    "                            loss3 += (IOU((x, y, w, h), (x_, y_, w_, h_)) - c_) ** 2 # yolo loss term 3\n",
    "                        yprobs[label_class[x, y, w, h]] = 1.  \n",
    "                    loss5 += ((yprobs - cell[-C:]) ** 2).sum() # yolo loss term 5\n",
    "                else:\n",
    "                    for k in range(4, B*5, 5):\n",
    "                        _c = cell[k]\n",
    "                        loss4 += _c ** 2 * lamba_noobj # yolo loss term 4\n",
    "        # print(\"xywh: \" , x_, y_, w_, h_, c_)\n",
    "        # print(\"label: \", x, y, w, h)\n",
    "    loss_df = pd.concat((loss_df, pd.DataFrame([[loss1.item(), loss2.item(), loss3.item(), loss4.item(), loss5.item()]], columns=loss_df.columns)), ignore_index=True)\n",
    "    return loss1 + loss2 + loss3 + loss4 + loss5, loss_df\n",
    "    # print(\"ret: \", res_mat.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iteration: 0, loss: 189.1861114501953\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m loss_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39ml1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39ml3\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39ml4\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39ml5\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mfor\u001b[39;00m _id, sample \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loader):\n\u001b[0;32m     13\u001b[0m         \u001b[39m# forward-propagate\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         batch, labels, classes \u001b[39m=\u001b[39m sample\n\u001b[0;32m     15\u001b[0m         res \u001b[39m=\u001b[39m yolo(batch\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\sxing\\Trading-detes\\SOTA\\yolo\\data\\VOC_Dataset.py:91\u001b[0m, in \u001b[0;36mVOC_Dataset.__getitem__\u001b[1;34m(self, ind)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[39m# class encoding\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     obj_classes\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_dict[classes[i]])\n\u001b[1;32m---> 91\u001b[0m img_arr \u001b[39m=\u001b[39m array(img\u001b[39m.\u001b[39;49mresize((\u001b[39m448\u001b[39;49m, \u001b[39m448\u001b[39;49m)), copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m/\u001b[39m \u001b[39m255.0\u001b[39m  \u001b[39m# normalize for RGB\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[39mreturn\u001b[39;00m transpose(img_arr, (\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)), pct_coords, obj_classes\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:2193\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2185\u001b[0m             \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mreduce(\u001b[39mself\u001b[39m, factor, box\u001b[39m=\u001b[39mreduce_box)\n\u001b[0;32m   2186\u001b[0m         box \u001b[39m=\u001b[39m (\n\u001b[0;32m   2187\u001b[0m             (box[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m factor_x,\n\u001b[0;32m   2188\u001b[0m             (box[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m factor_y,\n\u001b[0;32m   2189\u001b[0m             (box[\u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m factor_x,\n\u001b[0;32m   2190\u001b[0m             (box[\u001b[39m3\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m factor_y,\n\u001b[0;32m   2191\u001b[0m         )\n\u001b[1;32m-> 2193\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mim\u001b[39m.\u001b[39;49mresize(size, resample, box))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sys import modules\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "save_dir = os.path.expanduser(os.environ[\"YOLO_MODELS\"])\n",
    "\n",
    "optimizer = optim.Adam(yolo.parameters(), lr=1e-6)\n",
    "torch.cuda.empty_cache()\n",
    "loss_df = pd.DataFrame(columns=[\"l1\", \"l2\", \"l3\", \"l4\", \"l5\"])\n",
    "for epoch in range(1):\n",
    "    for _id, sample in enumerate(loader):\n",
    "        # forward-propagate\n",
    "        batch, labels, classes = sample\n",
    "        res = yolo(batch.to(device=device))\n",
    "        # print(res.shape, len(labels[2]), classes[2])\n",
    "        loss, loss_df = yolo_loss(res, labels, classes, loss_df)\n",
    "        # set_trace()\n",
    "\n",
    "        # back-propagate\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # record\n",
    "        if _id % 2000 == 0:\n",
    "            print(f\"Epoch {epoch}, iteration: {_id}, loss: {loss}\")\n",
    "            loss_df.to_csv(f\"{save_dir}/loss_latest.csv\")\n",
    "            # print(\"loss_df: \", loss_df)\n",
    "            # for col in loss_df.columns:\n",
    "            #     plt.plot(loss_df[col], label=col)\n",
    "            # plt.xlabel(\"iteration\")\n",
    "            # plt.ylabel(\"values\")\n",
    "            # plt.legend()\n",
    "            # plt.grid(True)\n",
    "            # plt.show()\n",
    "\n",
    "            checkpoint = {\n",
    "                'model': yolo.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'iteration': _id,\n",
    "                'train_loss': loss,\n",
    "                # 'val_loss': val_loss\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{save_dir}/yolov1_{epoch}_{_id}.pth\")\n",
    "            \n",
    "        # showing the image with labels\n",
    "        # res_img = Image.fromarray((batch[0] * 255).permute(1, 2, 0).byte().numpy())\n",
    "        # draw = ImageDraw.Draw(res_img)\n",
    "        # for pc in labels[0]:\n",
    "            # draw.rectangle((448*pc[0], 448*pc[1], 448*pc[2], 448*pc[3]), outline=\"red\")\n",
    "        # res_img.show()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
