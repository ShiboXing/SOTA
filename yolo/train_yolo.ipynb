{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26e480316b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"..\")\n",
    "from yolo.models import YOLOv1\n",
    "from yolo.data.VOC_Dataset import VOC_Dataset\n",
    "from data import DATA_HOME\n",
    "\n",
    "from ipdb import set_trace\n",
    "from torch.utils.data import DataLoader\n",
    "from numpy import array\n",
    "from multiprocessing import cpu_count\n",
    "import random \n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class dict:  {'tvmonitor': 0, 'dog': 1, 'cow': 2, 'bicycle': 3, 'bottle': 4, 'diningtable': 5, 'motorbike': 6, 'train': 7, 'boat': 8, 'horse': 9, 'bus': 10, 'aeroplane': 11, 'chair': 12, 'car': 13, 'sofa': 14, 'sheep': 15, 'bird': 16, 'cat': 17, 'pottedplant': 18, 'person': 19}\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "_voc_root = f\"{DATA_HOME}\\VOCdevkit\\VOC2007\"\n",
    "voc_ds = VOC_Dataset(_voc_root)\n",
    "BS = 2\n",
    "\n",
    "def collate_fn(data):\n",
    "    # output: 7 * 7 * 30\n",
    "    # S * S * ((x, y, w, h, confidence) * B=2 + C=20)\n",
    "    # make img batch and label batch\n",
    "    imgs, labels, classes = zip(*data)\n",
    "    # inhomegenous shape label, since each image has different number of objects\n",
    "    # label's dimension: (Batch size, # of objects in each image, 4 coords)\n",
    "    return torch.tensor(array(imgs), dtype=torch.float), labels, classes\n",
    "    \n",
    "if platform.system() == \"Windows\":\n",
    "    loader = DataLoader(voc_ds, batch_size=BS, pin_memory=True, shuffle=True, collate_fn=collate_fn)\n",
    "else:\n",
    "    loader = DataLoader(voc_ds, batch_size=BS, pin_memory=True, shuffle=True, num_workers=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = torch.randn(3, 448, 448).unsqueeze(0).to(device=device)\n",
    "yolo = YOLOv1().to(device=device)\n",
    "\n",
    "S = 7 # num of rows/cols\n",
    "C = 20 # num of classes\n",
    "B = 2 # num of bounding boxes\n",
    "\n",
    "lamba_coord = 5\n",
    "lamba_noobj = 0.5\n",
    "\n",
    "\n",
    "def IOU(output, label):\n",
    "    \"\"\"Calculate the intersection over union of two sets rectangles\n",
    "\n",
    "    Keyword arguments\n",
    "    both output and label are (x, y, w, h)\n",
    "    \"\"\"\n",
    "    \n",
    "    output = (\n",
    "        output[0] - output[2] / 2,\n",
    "        output[1] - output[3] / 2,\n",
    "        output[0] + output[2] / 2,\n",
    "        output[1] + output[3] / 2,\n",
    "    )\n",
    "\n",
    "    label = (\n",
    "        label[0] - label[2] / 2,\n",
    "        label[1] - label[3] / 2,\n",
    "        label[0] + label[2] / 2,\n",
    "        label[1] + label[3] / 2,\n",
    "    )\n",
    "\n",
    "    x_inter = min(output[2], label[2]) - max(output[0], label[0])\n",
    "    y_inter = min(output[3], label[3]) - max(output[1], label[1])\n",
    "\n",
    "    if x_inter <= 0.0 or y_inter <= 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    intersection = x_inter * y_inter\n",
    "\n",
    "    overlapped_union = (output[2] - output[0]) * (output[3] - output[1]) + (label[2] - label[0]) * (\n",
    "        label[3] - label[1]\n",
    "    )\n",
    "    \n",
    "    return intersection / (overlapped_union - intersection)\n",
    "\n",
    "# sanity checks of IOU\n",
    "coords = (0.25, 0.25, 0.5, 0.5)\n",
    "y_coords1 = (0.5, 0.575, 0.5, 0.35)\n",
    "y_coords2 = (0.575, 0.5, 0.35, 0.5)\n",
    "y_coords3 = (0.25, 0.25, 0.5, 0.5)\n",
    "y_coords4 = (0.25, 0, 0.5, 0)\n",
    "y_coords5 = (0.625, 0.375, 0.25, 0.75)\n",
    "y_coords6 = (0.2, 0.25, 0.2, 0.3)\n",
    "\n",
    "def float_eqs(a, b, decimal_pt):\n",
    "    eps = 10 ** (-decimal_pt)\n",
    "    return abs(a-b) < eps\n",
    "\n",
    "assert float_eqs(IOU(coords, y_coords1), 0.025 / (0.5*0.5 + 0.5*0.35 - 0.025), 5)\n",
    "assert float_eqs(IOU(coords, y_coords2), 0.025 / (0.5*0.5 + 0.5*0.35 - 0.025), 5)\n",
    "assert float_eqs(IOU(coords, y_coords3), 1, 5)\n",
    "assert float_eqs(IOU(coords, y_coords4), 0, 5)\n",
    "assert float_eqs(IOU(coords, y_coords5), 0, 5)\n",
    "assert float_eqs(IOU(coords, y_coords6), 0.06 / (0.5*0.5), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict as dd\n",
    "\n",
    "def yolo_loss(res_mat: torch.tensor, label_mat: list, class_mat: list):\n",
    "    \"\"\"calcalate batch yolo loss, @param res_mat: (batch_size, B*5+C, S, S)\"\"\"\n",
    "    loss = torch.tensor(0.).to(device=device)\n",
    "    \n",
    "    # calculate loss for every bounding box in every cell\n",
    "    for b, batch in enumerate(res_mat):\n",
    "        # assign labels bbox to cell indices\n",
    "        stride = 1. / S\n",
    "        label_inds = dd(list)\n",
    "        label_class = {}\n",
    "        for idx, (x, y, w, h) in enumerate(label_mat[b]):\n",
    "            xi, yi = int(x // stride), int(y // stride)\n",
    "            label_inds[(xi, yi)].append((x, y, w, h))\n",
    "            label_class[(x, y, w, h)] = class_mat[b][idx]\n",
    "        \n",
    "        # print(\"label class\", label_class, b, batch.shape)\n",
    "        # iterate cell and calculate loss\n",
    "        for i in range(batch.shape[1]):\n",
    "            for j in range(batch.shape[2]):\n",
    "                cell = batch[:, i, j]\n",
    "\n",
    "                if (i, j) in label_inds:\n",
    "                    yprobs = torch.tensor([0.] * C).to(device=device)\n",
    "                    for x, y, w, h in label_inds[i, j]:\n",
    "                        for k in range(0, B*5, 5):\n",
    "                            x_, y_, w_, h_, c_ = cell[k:k+5]\n",
    "                            w_, h_ = torch.max(torch.tensor(0.), w_), torch.max(torch.tensor(0.), h_)\n",
    "                            loss += lamba_coord * ((x-x_) ** 2 + (y-y_) ** 2) # yolo loss term 1\n",
    "                            loss += lamba_coord * ((w ** 0.5 - w_ ** 0.5)**2 + (h ** 0.5 - h_ ** 0.5)**2) # yolo loss term 2\n",
    "                            loss += (IOU((x, y, w, h), (x_, y_, w_, h_)) - c_) ** 2 # yolo loss term 3\n",
    "                        yprobs[label_class[x, y, w, h]] = 1.  \n",
    "                    loss += ((yprobs - cell[-C:]) ** 2).sum() # yolo loss term 5\n",
    "                else:\n",
    "                    for k in range(4, B*5, 5):\n",
    "                        _c = cell[k]\n",
    "                        loss += _c ** 2 * lamba_noobj\n",
    "                    \n",
    "                \n",
    "        \n",
    "    return loss\n",
    "    # print(\"ret: \", res_mat.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  tensor(5235554., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  tensor(4.6480e+08, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  tensor(2.5394e+10, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  tensor(9.2182e+14, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  tensor(2.4103e+13, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  tensor(1.8841e+16, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  tensor(6.9069e+13, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  tensor(6.5462e+17, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  tensor(2.1797e+18, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  tensor(2.9423e+17, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  tensor(4.7582e+20, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  tensor(4.2795e+19, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  tensor(1.6710e+17, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  tensor(1.0353e+17, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39m# back-propagate\u001b[39;00m\n\u001b[0;32m     23\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 24\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     25\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     27\u001b[0m \u001b[39m# record\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from sys import modules\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(yolo.parameters())\n",
    "\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    save_dir = os.environ[\"GDRIVE_MOUNT_DIR\"]\n",
    "else:\n",
    "    save_dir = os.path.expanduser(\"~/YOLO_MODELS\")\n",
    "\n",
    "for _id, sample in enumerate(loader):\n",
    "    \n",
    "    # forward-propagate\n",
    "    batch, labels, classes = sample\n",
    "    res = yolo(batch.to(device=device))\n",
    "    # print(res.shape, len(labels[2]), classes[2])\n",
    "    loss = yolo_loss(res, labels, classes)\n",
    "\n",
    "    # back-propagate\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # record\n",
    "    if _id and _id % 10 == 0:\n",
    "        print(\"loss \", loss)\n",
    "    if _id and _id % 100 == 0:\n",
    "        checkpoint = {\n",
    "            'model': yolo.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'iteration': _id,\n",
    "            'train_loss': loss,\n",
    "            # 'val_loss': val_loss\n",
    "        }\n",
    "        torch.save(checkpoint, f\"{save_dir}/tolov1_{_id}.pth\")\n",
    "    # showing the image with labels\n",
    "    # res_img = Image.fromarray((batch[0] * 255).permute(1, 2, 0).byte().numpy())\n",
    "    # draw = ImageDraw.Draw(res_img)\n",
    "    # for pc in labels[0]:\n",
    "    #     draw.rectangle((448*pc[0], 448*pc[1], 448*pc[2], 448*pc[3]), outline=\"red\")\n",
    "    # res_img.show()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
